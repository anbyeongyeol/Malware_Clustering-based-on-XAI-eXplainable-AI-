from selenium import webdriver
from pyshadow.main import Shadow
import time
import os
import string_list
import shutil
import json
import pandas as pd
import file_list

# 크롬 드라이버 경로
CHROMEDRIVER_PATH = 'C:\\~~\\chromedriver.exe'
# 검증 원하는 패밀리
MAL_TYPE = 'Backdoor'
SEARCH_CSV_PATH = f'{MAL_TYPE}_file.csv'
#detection로 고정
DETAIL_WEB = 'detection'

#CSV 파일에 넣을 Value List 생성
detection_value = []
family = []
error_hash = []

#시작 시 알림 함수
def start():
    print("================================================================================")
    print("[+] VT Crawling Start ! ")       
    start = time.time()
    if os.path.isdir('json_dic'):
        print('[+] json_dic 디렉토리 존재')
    else:
        os.mkdir('json_dic')
    return start

# 드라이버 접근
def get_driver():
    options = webdriver.ChromeOptions()
    options.add_experimental_option("excludeSwitches", ["enable-logging"])
    driver = webdriver.Chrome(CHROMEDRIVER_PATH, options=options)
    driver.implicitly_wait(3)
    return driver

#실제 값 들고오는 크롤러
def main_crawling(file, option, type):
    driver=get_driver()
    # 옵션에 따른 URL 접근
    for i in range(len(file)):
        try:
            link_info = 'https://www.virustotal.com/gui/file/{}/'.format(file[i])
            if option == 'details':
                link_info = link_info + str(option) 
            driver.get(link_info)
            time.sleep(1)
            
            #에러 발생 예외 처리(제대로 안돌아감)
            if "item-not-found" in driver.current_url:
                continue
            if "captcha" in driver.current_url:
                driver.back()
                time.sleep(1)
            if "too-many-requests" in driver.current_url:
                time.sleep(1)
                driver.get(link_info)
            print("================================================================================")
            print("[+] " + str(link_info) + " 접속")    
            #Shadow 객체 생성
            shadow = Shadow(driver)
            shadow.set_explicit_wait(20, 5)
        except:
            print("[+] " + str(file[i])  + " 링크 접속 중 에러 발생")
            error_hash.append(file[i])
        if option == 'detection':
            try:
                detection_element = shadow.find_element('vt-ui-expandable')
                detection_list = (detection_element.text).split('\n')
            except:
                print("[+] " + str(file[i])  + " Element, 데이터 크롤링 중 에러 발생")
                error_hash.append(file[i])
                continue
            crawling_parse(file[i], detection_list, option, type)
            time.sleep(1)
        else:
            print('Option Value Error')
        print(f"[+] 진행도 : {str(i+1)}/{str(len(file))}")
        
# VT 결과 파싱
def crawling_parse(file_name, data, option, type):
    if option == "detection":
        # 결과 벤더사 리스트
        vendor_list = []
        # 벤더사 진단명
        vendor_value = []
        for vl in range(int(len(data)/2+1)):
            try:
                if vl == 0:
                    continue
                else:
                    vendor_value.append(data[2*vl-1])
                    vendor_list.append(data[(2*vl)])
            except:
                print("[+] 진단명, 회사 파싱 중 오류 발생" )
        return Determining_Malware(file_name, vendor_list, vendor_value, type)


def Determining_Malware(file_name, company, detection_name, type):
    # 스코어 및 진단되지 않은 결과(정상) 제외
    type_error = detection_name.count('Unable to process file type')
    undetected = detection_name.count('Undetected')
    total = len(detection_name) - type_error
    detected = total - undetected

    #분류 결과(Top 15로 변경 예정)
    print("[+] " + str(file_name) + "의 Score : " + str(detected) + "/" + str(total))

    # 라벨링 작업 진행
    if detected <= 1:
        print("[+] " + str(file_name) + "정상으로 분류")
        detection_value.append('0')

    else:
        print("[+] " + str(file_name) + "악성으로 분류")
        detection_value.append('1')
    # Json 생성
    list_to_dictionary(file_name, company, detection_name, type)

# 해당 코드에서 사용안됨
def label_family(classification, max):
    return str(classification.index(max)+2)


# dictionary 변환 코드, 진단명이 아닌 문자열 제외
def list_to_dictionary(file_name, company, detection_name, type):
    vendor_list = company
    if "Do you want to automate checks?" in vendor_list:
        vendor_list.remove("Do you want to automate checks?")
    if "Do you want to automate checks?" in detection_name:
        detection_name.remove("Do you want to automate checks?")
    dictionary = {vendor_list[d] : detection_name[d] for d in range(len(detection_name))}

# 확장자 제외
    slice_filename = file_name[:-4]
    # json 명 
    json_name = f"json_dic\\{type}\\{str(file_name)}.json"
    
    classification_list = string_list.classification_list()
    detection_name_string = ''.join(detection_name)
    
    with open(json_name, "w") as json_file:
        json.dump(dictionary, json_file, indent=4, sort_keys=True)
        for cl in range(len(classification_list)):
            count = 0
            count = detection_name_string.count(classification_list[cl])
            if cl == 0:
                dic = {classification_list[cl] : count}
            else:
                dic[classification_list[cl]] = count
        
        max_value = class_tag(dic)
        print("[+] String 카운트 수 : " + str(dic))
        print("[+] 분류 결과 : " + str(max_value))
        
        # family.append(label_family(classification_list, max_value))
        json.dump(dic, json_file, indent=4, sort_keys=True)
    print("[+] " + str(json_name) + "파일 변환 완료")

# 해당 코드도 사용 안함
def class_tag(dictionary):
    # max_key = [kc for kc, vc in dictionary.items() if max(dictionary.values()) == vc]
    max_key = max(dictionary, key=dictionary.get)
    return max_key


if __name__ == '__main__':
    # Json 디렉토리 존재 유무 검사 및 시간 체크
    start = start()
    #CSV 파일의 SHA 목록 획득
    file_list = file_list.get_file(SEARCH_CSV_PATH, MAL_TYPE)
    
    crawling_data = main_crawling(file_list, DETAIL_WEB, MAL_TYPE)

    print("총 걸린 분류 시간 :", time.time() - start)
    print("[+] 작업 완료")
    #파서 
